# DPDM65 
## ü¶ñ SC 637 802 Data Pre-processing and Data Mining
### ‡∏Å‡∏£‡∏£‡∏ì‡∏¥‡∏Å‡∏≤‡∏£‡πå ‡∏ß‡∏¥‡∏£‡∏±‡∏ä‡∏ß‡∏≤  ‡∏£‡∏´‡∏±‡∏™‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤ 655020006-1


> # ![image](https://user-images.githubusercontent.com/59467239/176434509-d59b8c23-6b4f-436c-821f-1d9aaaad0f12.png)


![Grading image](grading.png) 


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ‚ú®Table of contents

---


> # Chapter 1. Introduction (‡∏ö‡∏ó‡∏ô‡∏≥)

- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/01Intro.jpg) 
  - [ ] Why Data Mining?
  - [ ] Knowledge Discovery (KDD) Process
  - [ ] Data Mining in Business Intelligence
  - [ ] KDD Process: A View from ML and Statistics
  - [ ] Data Mining Functions:
    - (2) Pattern Discovery
    - (3) Classification
    - (4) Cluster Analysis
    - (5) Outlier Analysis
    
- [x] Code
  - [ ] [‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Python ‡∏ö‡∏ô Google Colab](https://github.com/WiratchawaKannika/DPDM65/blob/main/Introduction.ipynb) 


> # Chapter 2. Getting to Know Your Data (‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/02Data.jpg) 
  - [ ] Data Objects and Attribute Types
  - [ ] Basic Statistical Descriptions of Data (‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)
  - [ ] Data Visualization
  - [ ] Measuring Data Similarity and Dissimilarity (‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
  
- [x] Code
  - [ ] [1. Basic python](https://github.com/WiratchawaKannika/DPDM65/blob/main/Data101_(Chapter2).ipynb)
    - ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ Variable (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£)
    - ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£
    - ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£
    - Check /‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£
    - Data structure (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
    - ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á list
    - list slicing
    - Advance list slicing
    - Loop (‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ com ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡πÜ‡∏Å‡∏±‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÜ‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏£‡∏≠‡∏ö)
    - Nested loop
    - Conditional Statement (if statement)
    - Function
  - [ ] [2. ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏ô pandas/ Visulization](https://github.com/WiratchawaKannika/DPDM65/blob/main/pandas101.ipynb)
    - ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1 Eyesball the Data 
    - ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2 Statical deacriptive (‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏£‡∏£‡∏ì‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)
    - ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 3.Boxplot ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
    - ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 4 Histogram 
    - ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Query(indexing)
    - Groupby
    - Data Visulization
      - Simple Line Plots
      - Scatter plot 
      - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Font ‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô matplotlib (Google Colab)
  - [ ] [3. Additional content](https://github.com/WiratchawaKannika/DPDM65/blob/main/Data102_(Chapter2).ipynb)
  
  
> # Chapter 3. Data Preprocessing (‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/03Preprocessing.jpg) 
  - Data Cleaning (‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
  - Data Integration (‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô)
  - Data Reduction and Transformation (‡∏Å‡∏≤‡∏£‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
  - Dimensionality Reduction (‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏°‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
  
- [x] Code
  - [ ] [preprocessing](https://github.com/WiratchawaKannika/DPDM65/blob/main/preprocessing.ipynb)
    - Data Cleaning
      - Check missing data
      - Dealing with missing data
      - delete records with missing data
      - ‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤ missing ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (class ‡πÉ‡∏´‡∏°‡πà, ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
      - ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà missing ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤ mean ‡∏£‡∏ß‡∏°
      - ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà missing ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤ mean ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°
    - ‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡πÅ‡∏Å‡∏ô X (‡πÄ‡∏û‡∏¥‡πà‡∏° feature ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö Data)
      - Pandas DataFrame merge 
      - pandas map
    - Smooth data
    - Create pandas df & save pandas df
  
  
> # Chapter 4. Mining Frequent Patterns, Association and Correlations: Basic Concepts and Methods (‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/06FPBasic.jpg) 
  - [ ] What Is Pattern Discovery?
  - [ ] Pattern Discovery: Why Is It Important?
  - [ ] Basic Concepts: k-Itemsets and Their Supports
  - [ ] Basic Concepts: Frequent Itemsets (Patterns)
  - [ ] From Frequent Itemsets to Association Rules
  - [ ] Limitation of the Support-Confidence Framework
  - [ ] Interestingness Measure: Lift
 
 
> # Chapter 5. Classification 
>> ## Classification: Basic Concepts
- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/08ClassBasic.jpg)
   - [ ] Classification: Model construction from a set of training data
   - [ ] Decision tree induction, Bayes classification methods, linear classifier, ...
   - [ ] Gain Ratio: A Refined Measure for Attribute Selection
   - [ ] Overfitting and Tree Pruning
   - [ ] Classifier Evaluation Metrics: Precision and Recall, and F-measures
   - [ ] Classifier Evaluation: Holdout & Cross-Validation
   
>> ## Classification: Advanced Methods
- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 1 [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/09ClassAdvanced-1.png)
- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 2 [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/09ClassAdvanced-2.png)
- [x] ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 3 [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Note/09ClassAdvanced-3.png)
   - [ ] Lazy vs. Eager Learning
   - [ ] Lazy Learner: Instance-Based Methods
   - [ ] The k-Nearest Neighbor Algorithm
   
- [x] Code
  - [ ] [Classification & Cross-Validation](https://github.com/WiratchawaKannika/DPDM65/blob/main/Classification.ipynb)
    - Data Preparation
    - Data Mining ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Classification
    - Decision Tree (General)
    - ‡∏ó‡∏≥ Cross Validation ‡∏´‡∏≤ Model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 
      - 1. Decision Tree (Dtree) 
      - 2. K-Neighbors (KNN) 
      - 3. Random Forests 
    
> # Mini Project
- [x] ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏°‡∏≠‡∏ö‡∏´‡∏°‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ PPT ‡πÅ‡∏•‡∏∞ Code ‡∏à‡∏≤‡∏Å Git project
  - [ ] Interesting Paper (Project) : [Robust Physical-World Attacks on Deep Learning Visual Classification](https://openaccess.thecvf.com/content_cvpr_2018/html/Eykholt_Robust_Physical-World_Attacks_CVPR_2018_paper)
  - [ ] [Official git](https://github.com/evtimovi/robust_physical_perturbations.git) 
  
- [x] [Code project ‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠](https://github.com/WiratchawaKannika/DPDM65/blob/main/PR2_FRCNN.ipynb)
- [x] PPT ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ [Click Here!](https://github.com/WiratchawaKannika/DPDM65/blob/main/Mini_Project/Paper-Robust%20Physical%20Perturbations(RP2).pdf)

----

     
